# ğŸš€ Quick Start: Database & Transcription Testing

## âš¡ 5-Minute Setup

### Step 1: Verify Everything is Running (1 min)
```bash
# Check MongoDB
lsof -i :27017
# Output: mongod should be listening

# Check Backend (port 3000)
lsof -i :3000
# If not running: cd server && npm run dev

# Check Frontend (port 5174)
lsof -i :5174
# If not running: npm run dev
```

### Step 2: Open the App (1 min)
```
Browser: http://localhost:5174
```

### Step 3: Create a Meeting (1 min)
```
1. Click "Create Meeting"
2. Note the Meeting ID (e.g., ABC123)
3. Copy the link
```

### Step 4: Join as Instructor (1 min)
```
1. Append ?role=instructor to the link
2. Example: http://localhost:5174/?role=instructor&id=ABC123
3. Allow microphone permissions
```

### Step 5: Wait for Audio Recording (1 min)
```
- AudioRecorder auto-records 60-second chunks
- After 60 seconds, watch backend console for:
  ğŸ™ï¸ [Transcription] Audio chunk received...
  âœ… [Transcription] Transcription complete...
  ğŸ’¾ [DB] Transcript saved to database...
```

---

## ğŸ” Verify Data in Database

### Check 1: Meeting Persisted
```bash
mongosh mongodb://localhost:27017/ly_conference --eval "
db.meetings.countDocuments()
" --quiet

# Should show: 1 or more
```

### Check 2: Transcripts Persisted (after audio)
```bash
mongosh mongodb://localhost:27017/ly_conference --eval "
db.transcripts.countDocuments()
" --quiet

# After instructor speaks: Should show 1 or more
```

### Check 3: Class Summary Persisted
```bash
mongosh mongodb://localhost:27017/ly_conference --eval "
db.classsummaries.countDocuments()
" --quiet

# After first transcript: Should show 1
```

---

## ğŸ“Š What's Saved Where

### In Memory (Instant, Live)
```
meetings.Map({
  'ABC123': {
    transcripts: [1, 2, 3...],
    classSummary: {...},
    participants: [...]
  }
})
```

### MongoDB (Persistent, Queryable)
```
db.meetings
  â””â”€ meetingId, title, status, createdAt

db.transcripts
  â””â”€ rawText, summary, duration, mimeType

db.classsummaries
  â””â”€ engagementScore, mainInsights, sentiment
```

---

## ğŸ¤ Transcription Pipeline

```
60 seconds pass
      â†“
AudioRecorder captures chunk
      â†“
emit('audio-chunk-recorded')
      â†“
Backend receives
      â†“
transcribeAudio() â†’ Gets mock/real transcript
      â†“
generateSummary() â†’ Creates 2-3 sentence summary
      â†“
store in meeting.transcripts
      â†“
save to db.transcripts
      â†“
generateAnalysisInsights() â†’ 3-4 actionable insights
      â†“
save to db.classsummaries
      â†“
emit('transcript-created') â†’ Real-time update to UI
      â†“
emit('class-summary-updated') â†’ UI shows insights
      â†“
User can click "Generate Question" â†’ Uses summary to create MCQs
```

---

## ğŸ“ Console Logs to Watch

### Backend Console (Terminal Running `npm run dev` in `server/`)

**Good Signs:**
```
âœ… MongoDB Connected: mongodb://localhost:27017/ly_conference
âœ… Server running on http://localhost:3000
âœ… Database persistence enabled
```

**During Audio Recording:**
```
ğŸ™ï¸ [Transcription] Audio chunk received from [socket] in room [ID]
â³ [Transcription] Starting transcription...
âœ… [Transcription] Transcription complete: Today we discussed...
ğŸ“ [Transcription] Summary generated
ğŸ’¾ [Transcription] Transcript stored (total: 1)
ğŸ’¾ [DB] Transcript saved to database with ID: [ObjectId]
ğŸ“Š [Transcription] Class summary updated: 3 insights
ğŸ’¾ [DB] Class summary saved to database with ID: [ObjectId]
```

### Frontend Console (Browser F12 â†’ Console)

**Good Signs:**
```
âœ… [AudioRecorder] Starting for instructor
ğŸ¤ [AudioRecorder] Chunk ready: 60000ms
ğŸ“Š [class-summary-updated] Class summary updated:
  â”œâ”€ totalTranscripts: 1
  â”œâ”€ engagementScore: 75
  â””â”€ mainInsights: ["âœ… High positive...", ...]
```

---

## ğŸ¯ Test Scenarios

### Scenario 1: Meeting Persistence âœ…
```
1. Create meeting
2. Close window
3. Restart backend
4. Check database still has meeting
   â†’ mongosh: db.meetings.countDocuments()
   â†’ Should still show 1+
```

### Scenario 2: Transcription Working âœ…
```
1. Create meeting
2. Join as instructor (?role=instructor)
3. Wait 60 seconds (1 audio chunk)
4. Check console for transcription logs
5. Query database: db.transcripts.countDocuments()
   â†’ Should be 1
```

### Scenario 3: Class Summary With Insights âœ…
```
1. After transcript is saved
2. Check console for: "ğŸ“Š [Transcription] Class summary updated: X insights"
3. Query database: db.classsummaries.findOne()
   â†’ Should have engagementScore and mainInsights
```

### Scenario 4: Generate Question From Summary âœ…
```
1. Wait for 1 transcription to complete
2. Instructor clicks "Generate Question"
3. Should generate MCQs from class insights
   (uses summary + engagement score for context)
```

---

## ğŸ†˜ Troubleshooting Quick Links

### Database not saving?
1. Check MongoDB is running: `lsof -i :27017`
2. Check server shows: `âœ… Database persistence enabled`
3. Look for specific save logs: `ğŸ’¾ [DB]`

### Transcription not happening?
1. Check audio is recording: Look for `ğŸ¤ [AudioRecorder] Chunk ready`
2. Check chunk received: Look for `ğŸ™ï¸ [Transcription] Audio chunk received`
3. Check it's instructor: URL should have `?role=instructor`

### Data showing in memory but not database?
1. Run: `mongosh mongodb://localhost:27017/ly_conference`
2. Query: `db.meetings.findOne()`
3. If empty: Database saves are failing, check error logs

---

## ğŸ“¦ What Should Increase

| Metric | Increases When | How to Check |
|--------|---|---|
| db.meetings | Create meeting | `db.meetings.countDocuments()` |
| db.transcripts | Instructor speaks (60s) | `db.transcripts.countDocuments()` |
| db.classsummaries | First transcript | `db.classsummaries.countDocuments()` |
| db.mcqs | Click "Generate Question" | `db.mcqs.countDocuments()` |

---

## âœ¨ Key Features

### âœ… Meeting Persistence
- Saves instantly to in-memory
- Saves to MongoDB for durability
- Survives server restart

### âœ… Audio Recording
- Auto-records 60-second chunks (instructor only)
- Sends to backend for processing
- Chunks can be chained together

### âœ… Transcription Pipeline
- Mock transcription (realistic test data)
- Real API ready (Whisper, Google Cloud)
- Generates summary from transcription
- Creates actionable insights

### âœ… Real-Time Updates
- Socket.IO broadcasts new transcripts
- Class summary updates live
- Engagement score updates in real-time
- UI shows insights as they're generated

### âœ… Question Generation
- Uses class summary for context
- Incorporates engagement score
- Calls Gemini API for MCQs
- Falls back to custom prompt

---

## ğŸ¬ Complete Test Flow (5-10 minutes)

```
1. Start all services (1 min)
   âœ… Backend running on 3000
   âœ… Frontend running on 5174
   âœ… MongoDB connected

2. Create meeting (1 min)
   âœ… Meeting ID shown
   âœ… Check console: "Meeting stored in memory"
   âœ… Check console: "Meeting saved to database"

3. Join as instructor (1 min)
   âœ… Allow microphone
   âœ… Wait for AudioRecorder to initialize
   âœ… Check console: "AudioRecorder starting for instructor"

4. Wait for audio chunk (1 min)
   âœ… After 60 seconds
   âœ… Check console: "Audio chunk received"
   âœ… Check console: "Transcription complete"

5. Verify database (2 min)
   âœ… mongosh: db.meetings.countDocuments() â†’ 1+
   âœ… mongosh: db.transcripts.countDocuments() â†’ 1+
   âœ… mongosh: db.classsummaries.countDocuments() â†’ 1

6. Test question generation (1 min)
   âœ… Click "Generate Question"
   âœ… Should show MCQs generated from summary
   âœ… Check: "Generated from class summary"

Total: 7-10 minutes to full verification âœ…
```

---

## ğŸš€ You're Ready!

Everything is set up and ready for testing. Start with the 5-minute setup above and work your way through the scenarios.

**Current Status:**
- âœ… Backend: Running
- âœ… Frontend: Running  
- âœ… MongoDB: Connected
- âœ… Meetings: Persisting (2 confirmed)
- âœ… Audio Recording: Ready
- âœ… Transcription: Ready
- âœ… Database Saving: Enhanced with logging

**Next Step:** Create a meeting and have the instructor record audio! ğŸ¤
