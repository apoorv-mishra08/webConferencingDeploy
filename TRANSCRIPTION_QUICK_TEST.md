# Quick Test Guide - Transcription Feature

## ğŸš€ Quick Start

### Step 1: Verify Servers Running
```bash
# Terminal 1 - Backend (should already be running on :3000)
cd /Users/ibrahimmir/03tailwindProps
npm run dev

# Terminal 2 - Frontend (should already be running on :5174)
cd /Users/ibrahimmir/03tailwindProps
npm run dev
```

Expected output:
- Backend: `âœ… Server running on http://localhost:3000`
- Frontend: `Local: http://localhost:5174`

---

## ğŸ§ª Test Scenario

### Part A: Setup Meeting

1. Open browser: `http://localhost:5174`
2. Create a meeting room (copy the room ID, e.g., `ABCD1234`)
3. Open **2 tabs**:
   - Tab 1: Instructor - `http://localhost:5174/meeting/ABCD1234?role=instructor`
   - Tab 2: Participant - `http://localhost:5174/meeting/ABCD1234`

### Part B: Audio Recording (Instructor)

4. **Instructor joins** (Tab 1)
   - Should see "AI Question Generator" panel
   - Panel should show: `â¹ï¸ Audio recording not started` (waiting for stream)
   - Backend should log:
     ```
     ğŸ‘¤ [join-room] Joining room: ABCD1234 as Instructor-xxxx
     ğŸ™ï¸ [AudioRecorder] Starting for instructor
     ```

5. **Verify AudioRecorder started**
   - Check browser DevTools Console (Tab 1)
   - Should see: `ğŸ™ï¸ [AudioRecorder] Chunk ready: 60000ms`
   - OR Server console should show: `âœ… [AudioRecorder] Initialized with MIME type: audio/webm`

### Part C: Wait for Transcription (1 minute)

6. **Wait 60 seconds** (audio chunk cycle)
   - Backend logs should appear:
     ```
     ğŸ™ï¸ [Transcription] Audio chunk received from socket_xyz
     â³ [Transcription] Starting transcription...
     âœ… [Transcription] Transcription complete: Today we discussed...
     ğŸ“ [Transcription] Summary generated
     ğŸ’¾ [Transcription] Transcript stored (total: 1)
     ğŸ“Š [Transcription] Class summary updated
     ```

7. **UI Update in Tab 1**
   - "Generate Question" panel should NOW show:
     ```
     ğŸ“Š Class Insights:
     â€¢ Today we discussed React hooks...
     
     [ğŸ¤ Generate Question]
     ```

### Part D: Generate Question from Summary

8. **Click "Generate Question"** button
   - Button should show loading: `â³ Generating...`
   - Backend logs:
     ```
     ğŸ¤” [Question] Generating question from class summary
     ğŸ“ [Question] Prompt built from summary...
     âœ… [Question] MCQ generated from summary and stored
     ğŸ“¤ broadcast('mcq-broadcast', {3 MCQs})
     ```

9. **See New MCQ Questions**
   - Tab 1 (Instructor) should show new poll with 3 questions
   - Tab 2 (Participant) should also see questions
   - Questions should be about React (from mock transcription)

### Part E: Custom Prompt Fallback

10. **Test custom prompt** (instructor)
    - Scroll down in "AI Question Generator" panel
    - Type: `Generate 2 questions about artificial intelligence`
    - Click blue "Send" button
    - New MCQs should appear

---

## ğŸ“Š What to Check

### âœ… Successful Signs

| Component | What to Look For |
|-----------|------------------|
| **Audio Recording** | Console: `âœ… Chunk ready` every 60s |
| **Transcription** | Console: `âœ… Transcription complete:` |
| **Summary** | UI shows insights in summary panel |
| **Engagement Score** | ClassSummary.engagementScore is 0-100 number |
| **Question Generation** | New MCQ appears after clicking button |
| **Chat** | Chat visible for instructor (flex-shrink-0 fix) |
| **Broadcast** | Both tabs see same questions simultaneously |

### âŒ Troubleshooting

| Problem | Solution |
|---------|----------|
| "Audio recording not started" stays forever | Check browser console for MediaRecorder error. Might need to grant permissions. |
| No logs in backend | Backend might not be running. Check terminal. |
| Port 5174 shows blank page | Frontend not built. Kill old process: `kill -9 $(lsof -t -i:5174)` then `npm run dev` |
| Socket connection fails | Check backend is actually running on :3000 |
| "No class insights available" error | Need to wait for first 60-second audio chunk. It doesn't happen immediately on join. |

---

## ğŸ” Console Log Locations

### Browser Console (Instructor Tab)

```javascript
// Should see every 60 seconds:
ğŸ™ï¸ [AudioRecorder] Started recording chunk
âœ… [AudioRecorder] Chunk ready: 60000ms
ğŸ¤ [AudioRecorder] Chunk ready: 60ms  // (smaller values are socket emit)

// When summary updates:
ğŸ“Š [class-summary-updated] Class summary updated: {insights, score, ...}
ğŸ“ [transcript-created] Transcript 1 received

// When new MCQ:
MCQ broadcasted: {id, prompt, mcqs}
```

### Server Console

```bash
# Every 60 seconds (audio chunk processed):
ğŸ™ï¸ [Transcription] Audio chunk received from socket_abc in room DEMO
ğŸ“ [Transcription] Summary generated
ğŸ’¾ [Transcription] Transcript stored (total: 1)
ğŸ“Š [Transcription] Class summary updated

# When generating from summary:
ğŸ¤” [Question] Generating question from class summary in room DEMO
âœ… [Question] MCQ generated from summary and stored

# When using custom prompt:
ğŸ“ [DEMO] Instructor requesting MCQ generation
ğŸ“ Prompt received: "Generate 2 questions..."
âœ… [DEMO] MCQs broadcasted successfully: 2 questions
```

---

## ğŸ“± Manual Test Commands (Browser Console)

```javascript
// Check if AudioRecorder initialized:
console.log(audioRecorderRef.current)  // Should show AudioRecorder object

// Manually trigger summary update:
socket.emit('get-class-analysis', { roomId: 'ABCD1234' })
// Listen: socket.on('class-analysis-received', console.log)

// Manually emit audio chunk (for testing):
socket.emit('audio-chunk-recorded', {
  roomId: 'ABCD1234',
  audioBase64: 'test123',
  duration: 60,
  mimeType: 'audio/webm',
  timestamp: new Date()
})
```

---

## â±ï¸ Expected Timing

| Event | When |
|-------|------|
| Instructor joins | Immediate |
| AudioRecorder initializes | Within 2s of join |
| First audio chunk ready | +60s after join |
| Transcription processed | +65s after join (5s processing time) |
| Summary shows in UI | +65s after join |
| Can click "Generate Question" | +65s after join |
| New MCQ appears | +67s after join (2s generation time) |

---

## ğŸ¬ Live Demo Flow (3 minutes)

**Timeline:**
- **0:00** - Instructor joins
- **0:02** - Audio recording starts (see logs)
- **1:00** - First audio chunk captured
- **1:05** - Transcription + summary ready in UI
- **1:07** - Instructor clicks "Generate Question"
- **1:09** - MCQs appear on screen
- **2:00** - Second audio chunk captured
- **2:05** - Updated summary (2 transcripts now)
- **2:07** - Click "Generate Question" again
- **2:09** - New MCQs based on updated summary

---

## ğŸ”§ If Nothing Shows Up

**Step 1: Check Backend Logs**
```bash
# Terminal with server.js running should show:
âœ… Server running on http://localhost:3000

# If not, kill and restart:
kill -9 $(lsof -t -i:3000)
cd /Users/ibrahimmir/03tailwindProps/server && npm run dev
```

**Step 2: Check Socket Connection**
```javascript
// In browser console:
socket.connected  // Should be TRUE
socket.id         // Should show socket ID (e.g., "abc123def456")
```

**Step 3: Check Frontend Code**
- Open `src/pages/MeetingRoom.jsx`
- Verify line ~220: Audio recorder initialization exists
- Verify line ~420: Event listeners for `class-summary-updated` exist

**Step 4: Check Network Tab**
- Open DevTools â†’ Network â†’ WS (WebSocket)
- Should see `socket.io` WebSocket connection
- Should see messages like `audio-chunk-recorded` every 60s

---

## âœ… Final Verification

After running the test:

- [ ] Backend running without errors
- [ ] Frontend loads at localhost:5174
- [ ] Can create and join meeting
- [ ] Instructor sees "Generate Question" panel
- [ ] After 60s, UI shows class insights
- [ ] Clicking button generates new MCQs
- [ ] Chat visible on instructor screen
- [ ] Console shows expected logs
- [ ] Custom prompt fallback works

**If all âœ…: Implementation is successful!**

---

## ğŸ› Debug Mode

Enable verbose logging:

```javascript
// In browser console, when on meeting page:
window.DEBUG = true;

// Then reload and watch for extra logs in:
// 1. Browser console (MeetingRoom.jsx logs)
// 2. Server console (server.js logs)
```

---

## ğŸ“¸ Screenshots to Compare

### Expected UI - Waiting State
```
AI Question Generator
ğŸ“ Status: â¹ï¸ Audio recording not started
```

### Expected UI - Ready State (after 60s)
```
AI Question Generator
ğŸ“ Class Insights:
  â€¢ Today we discussed React hooks...
  â€¢ We covered state management...
  â€¢ Participants asked about performance...

[ğŸ¤ Generate Question]  <- CLICKABLE BUTTON

---
Or use custom prompt:
[Enter custom topic...] [Send]
```

### Expected UI - Active MCQ
```
Active Polls
Poll #1 - Generated from class summary
Question: What is a React hook?
â—‹ Option 1
â—‹ Option 2
â—‹ Option 3
â—‹ Option 4

1/2 participants responded
```

---

**Ready to Test? Start the servers and follow the scenario above! ğŸš€**
